{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.导入必要库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.设置超参数和设备\n",
    "batch_size = 512\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.加载数据\n",
    "trainloader = torch.utils.data.DataLoader(datasets.MNIST('data', train=True, download=True,\n",
    "              transform=transforms.Compose([transforms.ToTensor()])), batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(datasets.MNIST('data', train=False, download=True,\n",
    "              transform=transforms.Compose([transforms.ToTensor()])), batch_size=batch_size, shuffle=True)\n",
    "print(\"训练数据形状:\", trainloader.dataset.data.shape)\n",
    "print(\"测试数据形式:\", testloader.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.创建模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)     # 输入通道1，输出通道6，卷积核5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)    # 输入通道6，输出通道16，卷积核5x5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)   # 全连接层，输入16*5*5，输出120\n",
    "        self.fc2 = nn.Linear(120, 84)   # 全连接层，输入120，输出84\n",
    "        self.clf = nn.Linear(84, 10)    # 分类层，输入84，输出10\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1\n",
    "        x = self.conv1(x)\n",
    "        x = F.sigmoid(x)    # 激活函数sigmoid()\n",
    "        x = F.avg_pool2d(x, kernel_size=2, stride=2)    # 平均池化层，kernel=2x2，步长2\n",
    "        # conv2\n",
    "        x = self.conv2(x)\n",
    "        x = F.sigmoid(x)    # 激活函数sigmoid()\n",
    "        x = F.avg_pool2d(x, kernel_size=2, stride=2)    # 平均池化层，2x2，步长2\n",
    "        # 展开，从第1维开始展开\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # 全连接层1\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)    # 激活函数sigmoid()\n",
    "        # 全连接层2\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)    # 激活函数sigmoid()\n",
    "        # 分类层\n",
    "        x = self.clf(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "epochs = 30\n",
    "accs, losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.训练和测试\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (x, y) in enumerate(trainloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # ---- 测试 ----\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    testloss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(testloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            testloss += F.cross_entropy(out, y).item()\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct += pred.eq(y).sum().item()\n",
    "\n",
    "    acc = correct / len(testloader.dataset)\n",
    "    testloss /= (batch_idx + 1)\n",
    "    accs.append(acc)\n",
    "    losses.append(testloss)\n",
    "    print('epoch:{}, loss:{:.4f}, acc:{:.4f}'.format(epoch, testloss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画 LOSS 和 ACC 曲线\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(losses, label='Test Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(accs, label='Test Acc')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"res1/loss_acc_curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算并绘制 Confusion Matrix\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in testloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        pred = out.max(dim=1)[1]\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(pred.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.savefig(\"res1/confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化每层卷积 + 池化的 Feature Map\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(testloader))\n",
    "    x = x.to(device)\n",
    "    # conv1 feature map\n",
    "    f1 = F.sigmoid(model.conv1(x))\n",
    "    p1 = F.avg_pool2d(f1, 2)\n",
    "    # conv2 feature map\n",
    "    f2 = F.sigmoid(model.conv2(p1))\n",
    "    p2 = F.avg_pool2d(f2, 2)\n",
    "\n",
    "def show_feature_maps(feature_maps, title, filename):\n",
    "    fm = feature_maps[0].cpu().numpy()   # 取 batch 的第一个样本\n",
    "    C = fm.shape[0]\n",
    "\n",
    "    cols = 6\n",
    "    rows = int(np.ceil(C / cols))\n",
    "\n",
    "    plt.figure(figsize=(12, rows * 2))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    for i in range(C):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(fm[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"res1/{filename}.png\")\n",
    "    plt.show()\n",
    "\n",
    "show_feature_maps(f1, \"Conv1 Feature Maps\", \"conv1_feature\")\n",
    "show_feature_maps(p1, \"Pool1 Feature Maps\", \"pool1_feature\")\n",
    "show_feature_maps(f2, \"Conv2 Feature Maps\", \"conv2_feature\")\n",
    "show_feature_maps(p2, \"Pool2 Feature Maps\", \"pool2_feature\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
